{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWb_Pph5GRXm"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['created_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Starting the MLflow Server\n",
    "\n",
    "Now you need to start the MLflow server in a new terminal.  \n",
    "**Note:** Before you start the MLflow server, create a folder named `mlruns` in the assignment directory.\n",
    "\n",
    "You need to run the command to start the MLflow server such that:\n",
    "\n",
    "1. The `lead_scoring_model_experimentation.db` (which you created above) is used as the backend store.\n",
    "2. `mlruns` folder is used as an artifact directory.\n",
    "3. The server runs on port **6006**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Steps to Follow\n",
    "\n",
    "1. Open a **new terminal**\n",
    "\n",
    "2. Create a folder named `mlruns`\n",
    "\n",
    "   ```bash\n",
    "   mkdir /home/mlruns\n",
    "   ```\n",
    "\n",
    "3. Start the MLflow server by running the following command:\n",
    "\n",
    "   ```bash\n",
    "   mlflow server \\\n",
    "      --backend-store-uri='sqlite:////home/mlflow/lead_scoring.db' \\\n",
    "      --default-artifact-root=\"/home/mlruns\" \\\n",
    "      --port=6006 \\\n",
    "      --host=0.0.0.0\n",
    "   ```\n",
    "\n",
    "4. In notebook, point MLflow Tracking URI to:\n",
    "\n",
    "   ```\n",
    "   http://0.0.0.0:6006\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Setting up Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "mlflow_db = '/home/mlflow/lead_scoring.db'\n",
    "mlruns_path = '/home/mlruns'\n",
    "\n",
    "db_dir = os.path.dirname(mlflow_db)\n",
    "\n",
    "# Create the directory if it doesn't exist\n",
    "if not os.path.exists(db_dir):\n",
    "    os.makedirs(db_dir, exist_ok=True)\n",
    "\n",
    "# Create the SQLite database (if not already existing)\n",
    "if not os.path.exists(mlflow_db):\n",
    "    conn = sqlite3.connect(mlflow_db)\n",
    "    conn.close()\n",
    "    print(f\"Database created at: {mlflow_db}\")\n",
    "else:\n",
    "    print(f\"Database already exists at: {mlflow_db}\")\n",
    "\n",
    "# Check and create the folder if it doesn't exist\n",
    "if not os.path.exists(mlruns_path):\n",
    "    os.makedirs(mlruns_path, exist_ok=True)\n",
    "    print(f\"Created directory: {mlruns_path}\")\n",
    "else:\n",
    "    print(f\"Directory already exists: {mlruns_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start mlflow from within notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import socket\n",
    "import os\n",
    "\n",
    "def is_port_in_use(port):\n",
    "    \"\"\"Check if a port is already being used.\"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "        return s.connect_ex(('0.0.0.0', port)) == 0 or s.connect_ex(('127.0.0.1', port)) == 0\n",
    "\n",
    "mlflow_port = 6006\n",
    "\n",
    "if not is_port_in_use(mlflow_port):\n",
    "    print(f\"Starting MLflow server on port {mlflow_port}...\")\n",
    "    subprocess.Popen([\n",
    "        \"mlflow\", \"server\",\n",
    "        \"--backend-store-uri\", \"sqlite:////home/mlflow/lead_scoring.db\",\n",
    "        \"--default-artifact-root\", \"/home/mlruns\",\n",
    "        \"--port\", str(mlflow_port),\n",
    "        \"--host\", \"0.0.0.0\"\n",
    "    ])\n",
    "else:\n",
    "    print(f\"MLflow is already running on port {mlflow_port}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://0.0.0.0:6006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pycaret experiment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup, compare_models, create_model, tune_model\n",
    "\n",
    "exp = setup(\n",
    "    data=data,\n",
    "    target='app_complete_flag',  \n",
    "    fold_shuffle=True, \n",
    "    session_id=42,\n",
    "    normalize=False, \n",
    "    transformation=False, \n",
    "    remove_multicollinearity=True, \n",
    "    multicollinearity_threshold = 0.95,\n",
    "    n_jobs=4,\n",
    "    use_gpu=False,\n",
    "    log_experiment=True,\n",
    "    log_plots=True,\n",
    "    log_data=True,\n",
    "    verbose=True,\n",
    "    log_profile=False,\n",
    "    silent=True,\n",
    "    experiment_name='Experiment_with_all_features'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 7. Model Experimentation with pycaret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are excluding\n",
    "\n",
    "```python\n",
    "['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_model = compare_models(sort='AUC', exclude=['gbc', 'knn', 'qda', 'dummy', 'svm', 'ada'], fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model which gives the highest accuracy (AUC)\n",
    "final_model = create_model(best_model, fold=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature importance plot\n",
    "plot_model(final_model, plot='feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_model, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_model, plot = 'confusion_matrix', plot_kwargs = {'percent' : True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 8. Model Experimentation after dropping features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training with Selected Features\n",
    "\n",
    "We will train the model using only the following significant features:\n",
    "\n",
    "```\n",
    "[\n",
    "    'total_leads_droppped',\n",
    "    'city_tier',\n",
    "    'referred_lead',\n",
    "    'app_complete_flag',\n",
    "    'first_platform_c', \n",
    "    'first_utm_medium_c', \n",
    "    'first_utm_source_c'\n",
    "]\n",
    "```\n",
    "\n",
    "Since we are using **tree-based models**, we do **not** require any transformations such as normalization or scaling.\n",
    "\n",
    "> Make sure to set up PyCaret with the correct configuration:\n",
    "- `normalize = False`\n",
    "- `transformation = False`\n",
    "\n",
    "This ensures the model leverages the raw structure of the data, which tree-based algorithms handle effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_features = [\n",
    "    'total_leads_droppped', \n",
    "    'city_tier',\n",
    "    'referred_lead',\n",
    "    'app_complete_flag',\n",
    "    'first_platform_c',\n",
    "    'first_utm_medium_c',\n",
    "    'first_utm_source_c'\n",
    "]\n",
    "\n",
    "data = data[significant_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import setup, compare_models, create_model, tune_model, get_config\n",
    "\n",
    "exp_tree = setup(\n",
    "    data=data,\n",
    "    target='app_complete_flag',\n",
    "    fold_shuffle=True,\n",
    "    session_id=42,\n",
    "    normalize=False,\n",
    "    transformation=False,\n",
    "    remove_multicollinearity=True,\n",
    "    multicollinearity_threshold=0.95,\n",
    "    n_jobs=4,\n",
    "    use_gpu=False,\n",
    "    log_experiment=True,\n",
    "    log_plots=True,\n",
    "    log_data=True,\n",
    "    verbose=True,\n",
    "    log_profile=False,\n",
    "    silent=True,\n",
    "    experiment_name='Experiment_with_reduced_features',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_models = ['rf', 'et', 'xgboost', 'lightgbm', 'dt']\n",
    "best_tree_model = compare_models(include=tree_models, sort='AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = create_model(best_tree_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_final_model = tune_model(final_model, \n",
    "                            optimize='AUC', \n",
    "                            fold=10, \n",
    "                            search_library='optuna')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tuned_final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import psutil\n",
    "\n",
    "# def kill_process_on_port(port):\n",
    "#     \"\"\"Find and kill process using the specified port.\"\"\"\n",
    "#     for proc in psutil.process_iter(['pid', 'name', 'connections']):\n",
    "#         try:\n",
    "#             for conn in proc.info['connections']:\n",
    "#                 if conn.status == psutil.CONN_LISTEN and conn.laddr.port == port:\n",
    "#                     print(f\"Killing process '{proc.info['name']}' with PID {proc.info['pid']} on port {port}\")\n",
    "#                     psutil.Process(proc.info['pid']).terminate()\n",
    "#                     return\n",
    "#         except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):\n",
    "#             continue\n",
    "#     print(f\"No process found on port {port}.\")\n",
    "\n",
    "# # Kill MLflow server running on port 6006\n",
    "# kill_process_on_port(6006)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Model-AfterFeature.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "144f839f29354f668dda71aa605216ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_383709fd8fda47ceadbf243d18428cf8",
      "max": 74,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_898da34f06fa4fd3be6fc028d246a379",
      "value": 74
     }
    },
    "383709fd8fda47ceadbf243d18428cf8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8239e3c9a1714d16a804cdf4239ec7f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "898da34f06fa4fd3be6fc028d246a379": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "94fbf501ef6e499387332ad398f2d3ff": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e278bc3113d41398166df961701e9fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a048df655c51475fb7369eb70702a575",
      "max": 4,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e52bcc4a1c3046bfb9e88d9e2d2218dd",
      "value": 4
     }
    },
    "a048df655c51475fb7369eb70702a575": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a18be2b61ba5486e9c132f9e5aa0e09e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Processing: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94fbf501ef6e499387332ad398f2d3ff",
      "max": 3,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8239e3c9a1714d16a804cdf4239ec7f3",
      "value": 3
     }
    },
    "e52bcc4a1c3046bfb9e88d9e2d2218dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
